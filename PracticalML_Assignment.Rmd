---
title: "Prediction Assignment (Coursera / Practical Machine Learning)"
author: "S. Gorgutsa"
date: "1/1/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive summary
The goal of this assignment is to predict which exercise was performed using the Weight Lifting Exercise Dataset [link] (http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har). This dataset contais data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

The training data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

## Configuring Environment and Loading Data
```{r message=FALSE}
library(caret)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)

```
```{r}
training_data_raw <- read.csv("pml-training.csv")
test_data_raw <- read.csv("pml-testing.csv")

```

## Exploratory Data analysis and cleaning
Preview data
```{r}
dim(training_data_raw)
dim(test_data_raw)
```
Thus we have 159 variables for 19622 samples in training set and 20 samples in test set.
However, if we would look on the data (output suppressed due to its excessive length) 
```{r include = FALSE}
head(test_data_raw)[,1:15]
```
we would see that: 
a. The first 7 non-numerical variables are not useful for our analysis / prediction model. b. There are a lot of NA values

### 
```{r}
## Remove non-numerical variables

training_data <- training_data_raw[,8:ncol(training_data_raw)]
test_data <- test_data_raw[,8:ncol(test_data_raw)]

### Remove variables with NA values, 95% threshold.
na_col <- sapply(training_data, function(x) mean(is.na(x))) > 0.95

training_data <- training_data[,na_col == FALSE]
test_data <- test_data[,na_col == FALSE]

dim(training_data)
dim(test_data)
```

Additionally, we can check if there are some variables in training set with nearly zero variance and exclude them from training and test sets as well. 

```{r}
zero_var <- nearZeroVar(training_data)

training_data_nzv <- training_data[,-zero_var]
test_data_nzv <- test_data[,-zero_var]

dim(training_data_nzv)
dim(test_data_nzv)
```

We can also check if the training data has the “classe” variable in it and the testing data has “problem_id” variable in it. As it will be needed for prediction part. 

```{r}
## last column in the training dataset
colnames(training_data_nzv)[ncol(training_data_nzv)]
## last column in the test dataset
colnames(test_data_nzv)[ncol(test_data_nzv)]
```

## Data partition 
Let us divide the available training dataset into two different parts using 60 /40 ratio. With one part (60% of the avaialbe data) being actual training set for the prediction model and 40% being the test set. 

```{r}
partition <- createDataPartition(training_data_nzv$classe, p=0.6, list=FALSE)
training <- training_data_nzv[partition,]
test <- training_data_nzv[-partition,]

dim(training)
```
## Prediction Model Seleciton
We can now test several most popular prediction models and see which one provides the highest accuracy. Namely we will test the Decision Tree, Random Forest and Gradient Boosting models.

### Decision Tree
```{r}
# Training
tree <- train(classe ~ ., data = training, method="rpart")

# Prediction
tree_prediction <- predict(tree, test)
confusionMatrix(tree_prediction, as.factor(test$classe))

```

Thus the accuracy of the Decision Tree model is around 49%.

### Random Forest 

```{r}
# Training
forest <- train(classe ~ ., data = training, method = "rf", ntree = 50)

# Prediction
forest_prediction <- predict(forest, test)
confusionMatrix(forest_prediction, as.factor(test$classe))
```
Thus the accuracy of the Random Forest model is 98.9%

### Gradient Boosting

```{r}
# Training
gradient <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE)
gradient$finalModel
```

```{r}
# Prediction
gradient_prediction <- predict(gradient, test)
confusionMatrix(gradient_prediction, as.factor(test$classe))
```

Thus the accuracy of the Gradient Boosting model is 96.3%

## Conclusion

Overall, the Random Forest and Gradient Boosting models have demonstrated the highest accuracy. If to compare their overall performance the Random Forest looks to be a more accurate one. 

```{r}
# Overall statistics for Random Forest Model
confusionMatrix(forest_prediction, as.factor(test$classe))$overall
```
```{r}
# Overall statistics for Gradient Boosting Model
confusionMatrix(gradient_prediction, as.factor(test$classe))$overall
```

## Applying Final model to original Test dataset
```{r}
Final_prediction <- predict(forest, test_data_nzv )
Final_prediction
```

